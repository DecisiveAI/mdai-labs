apiVersion: hub.mydecisive.ai/v1
kind: MdaiHub
metadata:
  labels:
    app.kubernetes.io/name: mdai-operator
    app.kubernetes.io/managed-by: kustomize
  name: mdaihub-sample
  namespace: mdai
spec:
  variables:
    - key: manual_filter
      type: manual
      dataType: string
      serializeAs:
        - name: "MANUAL_FILTER"
    - key: service_list
      serializeAs:
        - name: "SERVICE_LIST_REGEX"
          transformers:
            - type: join
              join:
                delimiter: "|"
        - name: "SERVICE_LIST_CSV"
          transformers:
            - type: join
              join:
                delimiter: ","
      # below properties are optional
      dataType: set
      storageType: "mdai-valkey"
    - key: team_list
      serializeAs:
        - name: "TEAM_LIST_REGEX"
          transformers:
            - type: join
              join:
                delimiter: "|"
        - name: "TEAM_LIST_CSV"
          transformers:
            - type: join
              join:
                delimiter: ","
      # below properties are optional
      dataType: set
      storageType: "mdai-valkey"
    - key: alerting_data_type
      dataType: string
      serializeAs:
        - name: "ALERTING_DATA_TYPE"
    - key: alerting_triggered
      dataType: boolean
      serializeAs:
        - name: "ALERT_TRIGGERED"

  prometheusAlerts:
    - name: top_talkers
      expr: 'sum(increase(bytes_received_by_service_total{mdai_service!=""}[1m])) by (mdai_service, data_type) > 800*1024'
      severity: warning
      for: 1m
      keep_firing_for: 1m
    - name: top_listeners
      expr: 'sum(increase(bytes_sent_by_service_total{mdai_service!=""}[1h])) by (mdai_service, data_type) > 10*1024*1024'
      severity: warning
      for: 15m
      keep_firing_for: 10m
    - name: top_team_talkers
      expr: 'sum(increase(bytes_received_by_team_region_total{team!=""}[1h])) by (team, data_type) > 10*1024*1024'
      severity: warning
      for: 3m
      keep_firing_for: 10m
    - name: anomalous_error_rate
      # two part query
      # first part checks if the error rate is a specific multiplier of the normal error rate over the last hour
      # second part ensures there is at least an hour's worth of data to check against, to prevent false-positives
      expr: 'sum(increase(error_logs_by_service_total[5m])) by (mdai_service) > 2 * sum(avg_over_time(increase(error_logs_by_service_total[5m])[1h:])) by (mdai_service) and (sum by (mdai_service) (error_logs_by_service_total offset 1h))'
      severity: warning
      for: 3m
      keep_firing_for: 3m
    - name: anomalous_mdai_error_rate
      # two part query
      # first part checks if the error rate is a specific multiplier of the normal error rate over the last hour
      # second part ensures there is at least an hour's worth of data to check against, to prevent false-positives
      expr: '(sum(increase(mdai_errors_by_component_total[5m])) by (service_name, instance) > 1.5 * sum(avg_over_time(increase(mdai_errors_by_component_total[5m])[1h:])) by (service_name, instance)) and (sum by (service_name, instance) (mdai_errors_by_component_total offset 1h))'
      severity: warning
      for: 3m
      keep_firing_for: 3m
    - name: errors_for_service1234
      expr: 'sum(increase(error_logs_by_service_total{mdai_service="service1234"}[5m])) by (mdai_service) > 500'
      severity: warning
      for: 3m
      keep_firing_for: 3m

  rules:
    - name: top_talkers_resolved
      when:
        alertName: top_talkers
        status: resolved
      then:
        - removeFromSet:
            set: service_list
            value: ${trigger:payload.labels.mdai_service}
    - name: top_talkers_firing
      when:
        alertName: top_talkers
        status: firing
      then:
        - addToSet:
            set: service_list
            value: ${trigger:payload.labels.mdai_service}
        - setVariable:
            scalar: alerting_data_type
            value: ${trigger:payload.labels.data_type}
        - setVariable:
            scalar: alerting_triggered
            value: "true"
    - name: top_team_talkers_resolved
      when:
        alertName: top_team_talkers
        status: resolved
      then:
        - removeFromSet:
            set: team_list
            value: "team"
    - name: top_team_talkers_firing
      when:
        alertName: top_team_talkers
        status: firing
      then:
        - addToSet:
            set: team_list
            value: "team"

    - name: anomalous_error_rate
      when:
        alertName: anomalous_error_rate
        status: firing
      then:
        - callWebhook:
            url:
              valueFrom:
                # Read the URL from a Secret (recommended)
                secretKeyRef: {name: slack-webhook-secret, key: url }
            templateRef: slackAlertTemplate
            templateValues:
              labels_val_ref_primary: mdai_service
              message: Service was >2x expected error rate for five minutes compared to the last hour!
              link_url: http://localhost:9090/alerts
              link_text: See alert in Prometheus

    - name: anomalous_mdai_error_rate
      when:
        alertName: anomalous_mdai_error_rate
        status: firing
      then:
        - callWebhook:
            url:
              valueFrom:
                # Read the URL from a Secret (recommended)
                secretKeyRef: { name: slack-webhook-secret, key: url }
            templateRef: slackAlertTemplate
            templateValues:
              labels_val_ref_primary: service_name
              message: MDAI Hub Component was >1.5x expected error rate for five minutes compared to the last hour!
              link_text: See alert in Prometheus
              link_url: http://localhost:9090/alerts
    - name: errors_for_service1234
      when:
        alertName: errors_for_service1234
        status: firing
      then:
        - callWebhook:
            url:
              valueFrom:
                # Read the URL from a Secret (recommended)
                secretKeyRef: { name: slack-webhook-secret, key: url }
            templateRef: slackAlertTemplate
            templateValues:
              labels_val_ref_primary: mdai_service
              message: Service had more than 500 errors in the last five minutes!
              link_text: See alert in Prometheus
              link_url: http://localhost:9090/alerts
        - callWebhook:
            # update owner and repo, provide a github-token secret for this action to work
            url: { value: https://api.github.com/repos/OWNER/REPO/actions/workflows/deploy.yml/dispatches }
            method: POST
            templateRef: jsonTemplate
            payloadTemplate:
              value: |-
                {
                  "ref": "${template:ref:-main}",
                  "inputs": {
                    "env": "${template:env:-prod}",
                    "build_id": "${trigger:id}"
                  }
                }
            templateValues:
              ref: main
              env: uat
            headersFrom:
              Authorization:
                # requires a secret with the GitHub token in the same namespace as the MDAiHub instance
                secretKeyRef: { name: github-token, key: authorization }
            headers:
              Accept: application/vnd.github+json
              X-GitHub-Api-Version: "2022-11-28"
              Content-Type: application/json