apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: gateway
  namespace: mdai
spec:
  managementState: managed
  image: otel/opentelemetry-collector-contrib:0.122.0
  replicas: 1
  resources:
    limits:
      memory: "512Mi"
      cpu: "200m"
    requests:
      memory: "256Mi"
      cpu: "100m"
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317

    connectors:
      datadog/connector:
        traces:
          trace_buffer: 1000  # default

    processors:
      tail_sampling:
        decision_wait: 10s # TODO do we have a number for this?
        # expected_new_traces_per_sec: _ # TODO: do we have a number for this?
        policies:
          - name: keep-all-the-errors
            type: and
            and:
              and_sub_policy:
                - name: error-sampling
                  type: status_code
                  status_code:
                    status_codes:
                      - ERROR
          - name: probabilistic-sample-top-talkers
            type: and
            and:
              and_sub_policy:
                - name: services-using-tail-sampling
                  type: string_attribute
                  string_attribute:
                    key: operation
                    values:
                      - "high-volume-op"
                - name: probabilistic-policy
                  type: probabilistic
                  probabilistic:
                    sampling_percentage: 10  # sample 10%
          - name: always-sample-non-top-talkers
            type: ottl_condition
            ottl_condition: {
              error_mode: ignore,
              span: [
                "attributes[\"operation\"] != \"high-volume-op\"",
              ]
            }

      batch:
        send_batch_size: 50
        send_batch_max_size: 200
        timeout: 10s

    exporters:
      debug:
        verbosity: detailed
      datadog/exporter:
        api:
          site: ${env:DD_SITE}
          key: ${env:DD_API_KEY}

    service:
      pipelines:
        traces:
          # ensure metrics are computed before sampling, ensuring their accuracy
          receivers: [otlp]
          processors: [batch]
          exporters: [datadog/connector]
        traces/datadog:
          receivers: [datadog/connector]
          processors: [tail_sampling, batch]
          exporters: [debug, datadog/exporter]
        metrics:
          receivers: [datadog/connector]
          processors: [batch]
          exporters: [datadog/exporter]