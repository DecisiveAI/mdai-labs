apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: trace-balancer
  namespace: mdai
spec:
  serviceAccount: loadbalancer
  image: otel/opentelemetry-collector-contrib:0.127.0
  replicas: 1
  resources:
    limits:
      memory: "256Mi"
      cpu: "200m"
    requests:
      memory: "128Mi"
      cpu: "100m"
  config:
    receivers:
      otlp/from_agent:
        protocols:
          grpc: 
            endpoint: '0.0.0.0:4317'
          http: 
            endpoint: '0.0.0.0:4318'

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133

    processors:
      deltatocumulative: {}

    exporters:
      loadbalancing:
        protocol:
          otlp:
            compression: gzip
            tls:
              insecure: true
        resolver:
          k8s:
            service: gateway-collector-headless.mdai
      prometheus:
        endpoint: 0.0.0.0:8899
        metric_expiration: 180m
        resource_to_telemetry_conversion:
          enabled: true

    connectors:
      count/service:
        spans:
          trace.span.service.count:
            description: Span count by service.
            conditions:
              - 'IsRootSpan()'

    service:
      telemetry:
        resource:
          mdai-logstream: collector
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: "0.0.0.0"
                    port: 8888
      extensions: [health_check]
      pipelines:
        traces:
          receivers: [otlp/from_agent]
          processors: []
          exporters: [loadbalancing, count/service]
        metrics:
          receivers: [count/service]
          processors: [deltatocumulative]
          exporters: [prometheus]
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: gateway
  namespace: mdai
spec:
  managementState: managed
  image: otel/opentelemetry-collector-contrib:0.127.0
  replicas: 1
  resources:
    limits:
      memory: "512Mi"
      cpu: "200m"
    requests:
      memory: "256Mi"
      cpu: "100m"
  config:
    receivers:
      otlp/from_lb:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317

    extensions:
      health_check:
        endpoint: "${env:MY_POD_IP}:13133"

    processors:
      tail_sampling:
        decision_wait: 10s # TODO do we have a number for this?
        # expected_new_traces_per_sec: _ # TODO: do we have a number for this?
        policies:
          - name: keep-all-the-errors
            type: and
            and:
              and_sub_policy:
                - name: error-sampling
                  type: status_code
                  status_code:
                    status_codes:
                      - ERROR
          - name: probabilistic-sample-top-talkers
            type: and
            and:
              and_sub_policy:
                - name: services-using-tail-sampling
                  type: string_attribute
                  string_attribute:
                    key: operation
                    values:
                      - "high-volume-op"
                - name: probabilistic-policy
                  type: probabilistic
                  probabilistic:
                    sampling_percentage: 10  # sample 10%
          - name: always-sample-non-top-talkers
            type: ottl_condition
            ottl_condition: {
              error_mode: ignore,
              span: [
                "attributes[\"operation\"] != \"high-volume-op\"",
              ]
            }

      batch:
        send_batch_size: 50
        send_batch_max_size: 200
        timeout: 10s

    exporters:
      debug/to_vendor:
        verbosity: detailed
      
    service:
      telemetry:
        resource:
          mdai-logstream: collector
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: "0.0.0.0"
                    port: 8888
      extensions: [health_check]
      pipelines:
        traces:
          # ensure metrics are computed before sampling, ensuring their accuracy
          receivers: [otlp/from_lb]
          processors: [tail_sampling, batch]
          exporters: [debug/to_vendor]
