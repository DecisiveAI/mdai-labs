apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  labels:
    mdaihub-name: mdaihub-sample
  name: gateway
  namespace: mdai
spec:
  managementState: managed
  image: otel/opentelemetry-collector-contrib:latest
  replicas: 2
  resources:
    limits:
      memory: "512Mi"
      cpu: "200m"
    requests:
      memory: "256Mi"
      cpu: "100m"
  envFrom:
    - configMapRef:
        name: mdaihub-sample-variables
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317

    connectors:
      datadog/connector:
        traces:
          trace_buffer: 1000  # default

    processors:
      tail_sampling:
        decision_wait: 10s # TODO do we have a number for this?
        # expected_new_traces_per_sec: _ # TODO: do we have a number for this?
        policies:
          - name: keep-all-the-errors
            type: and
            and:
              and_sub_policy:
                - name: error-sampling
                  type: status_code
                  status_code:
                    status_codes:
                      - ERROR
          - name: probabilistic-sample-super-loud-services
            type: and
            and:
              and_sub_policy:
                - name: match-super-loud-services
                  type: ottl_condition
                  ottl_condition:
                    error_mode: ignore
                    span:
                      - "ContainsValue(Split(\"${env:SUPER_LOUD_SERVICE_LIST}\", \",\"), resource.attributes[\"service.name\"])"
                - name: super-loud-probabilistic-policy
                  type: probabilistic
                  probabilistic:
                    sampling_percentage: 10 # 10% sampling
          - name: probabilistic-sample-loud-services
            type: and
            and:
              and_sub_policy:
                - name: match-loud-services
                  type: ottl_condition
                  ottl_condition:
                    error_mode: ignore
                    span:
                      - "ContainsValue(Split(\"${env:LOUD_SERVICE_LIST}\", \",\"), resource.attributes[\"service.name\"])"
                - name: loud-probabilistic-policy
                  type: probabilistic
                  probabilistic:
                    sampling_percentage: 50  # 50% sampling
          - name: always-sample-quiet-services
            type: always_sample # fallthrough

      batch:
        send_batch_size: 50
        send_batch_max_size: 200
        timeout: 10s

    exporters:
      datadog/exporter:
        api:
          site: ${env:DD_SITE_URL}
          key: ${env:DD_API_KEY}

    service:
      pipelines:
        traces:
          # ensure metrics are computed before sampling, ensuring their accuracy
          receivers: [otlp]
          processors: [batch]
          exporters: [datadog/connector]
        traces/datadog:
          receivers: [datadog/connector]
          processors: [tail_sampling, batch]
          exporters: [datadog/exporter]
        metrics:
          receivers: [datadog/connector]
          processors: [batch]
          exporters: [datadog/exporter]
